{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8242d48b-1255-4d11-ba5f-0381ff441620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\kopo\\\\devcode\\\\Session_chatgpt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": ["import json\nimport os\nfrom flask import Flask, render_template, request, jsonify\nfrom openai import OpenAI\n\nclient = OpenAI(api_key='OPENAI_API_KEY')\nfrom openai.error import RateLimitError\n\napp = Flask(__name__)\n# CHANGE OPENAI_API_KEY -> YOUR_API_KEY\n# openai.api_key = 'sk-JUg....'\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/gpt4', methods=['GET', 'POST'])\ndef gpt4():\n    user_input = request.args.get('user_input') if request.method == 'GET' else request.form['user_input']\n    messages = [{\"role\": \"user\", \"content\": user_input}]\n\n    try:\n        response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n        messages=messages)\n        content = response.choices[0].message.content\n    except RateLimitError:\n        content = \"The server is experiencing a high volume of requests. Please try again later.\"\n\n    return jsonify(content=content)\n\nif __name__ == '__main__':\n    app.run(debug=True)"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
